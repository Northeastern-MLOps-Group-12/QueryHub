"""
QueryHub Prometheus Metrics - COMPLETE Implementation
Tracks: System resources, RPS, Latency, LLM tokens, SQL complexity, Errors
"""

from prometheus_client import Counter, Histogram, Gauge, Summary, Info
import time
import psutil
import os
from functools import wraps
from contextlib import contextmanager
from typing import Optional

# ============================================================================
# SYSTEM RESOURCE METRICS (CPU, Memory, Disk)
# ============================================================================

system_cpu_usage = Gauge(
    'queryhub_system_cpu_usage_percent',
    'System CPU usage percentage'
)

system_memory_usage = Gauge(
    'queryhub_system_memory_usage_percent',
    'System memory usage percentage'
)

system_memory_available = Gauge(
    'queryhub_system_memory_available_bytes',
    'Available system memory in bytes'
)

system_disk_usage = Gauge(
    'queryhub_system_disk_usage_percent',
    'System disk usage percentage'
)

process_cpu_usage = Gauge(
    'queryhub_process_cpu_usage_percent',
    'QueryHub process CPU usage percentage'
)

process_memory_usage = Gauge(
    'queryhub_process_memory_usage_bytes',
    'QueryHub process memory usage in bytes'
)

# ============================================================================
# REQUEST RATE METRICS (RPS)
# ============================================================================

requests_per_second = Gauge(
    'queryhub_requests_per_second',
    'Current requests per second'
)

query_requests_total = Counter(
    'queryhub_query_requests_total',
    'Total number of query requests',
    ['user_id', 'status']
)

# ============================================================================
# LATENCY METRICS
# ============================================================================

query_processing_duration = Histogram(
    'queryhub_query_processing_duration_seconds',
    'End-to-end query processing time',
    ['user_id'],
    buckets=(0.5, 1.0, 2.5, 5.0, 10.0, 20.0, 30.0, 60.0, 120.0, float('inf'))
)

# ============================================================================
# LLM TOKEN METRICS (Time to First Token, Tokens/Second)
# ============================================================================

llm_time_to_first_token = Histogram(
    'queryhub_llm_time_to_first_token_seconds',
    'Time until first token is received from LLM',
    ['operation', 'model'],
    buckets=(0.1, 0.25, 0.5, 1.0, 2.0, 3.0, 5.0, 10.0, float('inf'))
)

llm_total_generation_time = Histogram(
    'queryhub_llm_total_generation_time_seconds',
    'Total time to generate complete LLM response',
    ['operation', 'model'],
    buckets=(0.5, 1.0, 2.5, 5.0, 10.0, 20.0, 30.0, float('inf'))
)

llm_tokens_generated = Counter(
    'queryhub_llm_tokens_generated_total',
    'Total tokens generated by LLM',
    ['operation', 'model']
)

llm_tokens_per_second = Gauge(
    'queryhub_llm_tokens_per_second',
    'Current LLM generation speed (tokens/second)',
    ['operation', 'model']
)

llm_average_time_per_token = Gauge(
    'queryhub_llm_average_time_per_token_seconds',
    'Average time per token generated',
    ['operation', 'model']
)

# ============================================================================
# COMPONENT TIMING METRICS
# ============================================================================

database_selection_duration = Histogram(
    'queryhub_database_selection_duration_seconds',
    'Time taken to select database',
    buckets=(0.1, 0.25, 0.5, 1.0, 2.5, 5.0, float('inf'))
)

sql_generation_duration = Histogram(
    'queryhub_sql_generation_duration_seconds',
    'Time taken to generate SQL',
    ['retry_attempt'],
    buckets=(0.5, 1.0, 2.5, 5.0, 10.0, 30.0, float('inf'))
)

sql_validation_duration = Histogram(
    'queryhub_sql_validation_duration_seconds',
    'Time taken to validate SQL',
    buckets=(0.01, 0.05, 0.1, 0.25, 0.5, 1.0, float('inf'))
)

sql_execution_duration = Histogram(
    'queryhub_sql_execution_duration_seconds',
    'Time taken to execute SQL',
    ['db_name', 'db_type'],
    buckets=(0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, float('inf'))
)

visualization_generation_duration = Histogram(
    'queryhub_visualization_generation_duration_seconds',
    'Time taken to generate visualizations',
    ['intent'],
    buckets=(0.5, 1.0, 2.5, 5.0, 10.0, 30.0, float('inf'))
)

gcs_upload_duration = Histogram(
    'queryhub_gcs_upload_duration_seconds',
    'Time taken to upload to GCS',
    buckets=(0.5, 1.0, 2.5, 5.0, 10.0, 30.0, float('inf'))
)

# ============================================================================
# ERROR METRICS
# ============================================================================

sql_validation_failures = Counter(
    'queryhub_sql_validation_failures_total',
    'Total SQL validation failures',
    ['failure_type']
)

sql_execution_errors = Counter(
    'queryhub_sql_execution_errors_total',
    'Total SQL execution errors',
    ['db_name', 'db_type', 'error_type']
)

retry_attempts = Histogram(
    'queryhub_retry_attempts',
    'Distribution of retry attempts per query',
    buckets=(0, 1, 2, 3, 4, 5, float('inf'))
)

workflow_errors = Counter(
    'queryhub_workflow_errors_total',
    'Total workflow errors',
    ['error_stage', 'error_type']
)

# ============================================================================
# DATABASE METRICS
# ============================================================================

database_queries = Counter(
    'queryhub_database_queries_total',
    'Total queries per database',
    ['db_name', 'user_id']
)

database_selection_similarity = Histogram(
    'queryhub_database_selection_similarity',
    'Database selection similarity scores',
    buckets=(0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0)
)

# ============================================================================
# SQL COMPLEXITY METRICS (NEW)
# ============================================================================

sql_complexity_distribution = Counter(
    'queryhub_sql_complexity_distribution_total',
    'Distribution of SQL queries by complexity type',
    ['complexity_type', 'db_type']
)

sql_complexity_score = Histogram(
    'queryhub_sql_complexity_score',
    'Numeric complexity score (1-7, higher = more complex)',
    ['db_type'],
    buckets=(1, 2, 3, 4, 5, 6, 7, 8)
)

sql_features_detected = Counter(
    'queryhub_sql_features_detected_total',
    'Count of specific SQL features detected in queries',
    ['feature_type', 'db_type']
)

sql_average_complexity_score = Gauge(
    'queryhub_sql_average_complexity_score',
    'Current average complexity score across recent queries',
    ['db_type']
)

sql_join_count = Histogram(
    'queryhub_sql_join_count',
    'Number of JOINs in SQL queries',
    ['db_type'],
    buckets=(0, 1, 2, 3, 4, 5, 10, float('inf'))
)

sql_subquery_nesting_level = Histogram(
    'queryhub_sql_subquery_nesting_level',
    'Nesting level of subqueries',
    ['db_type'],
    buckets=(0, 1, 2, 3, 4, 5, float('inf'))
)

# ============================================================================
# VISUALIZATION METRICS
# ============================================================================

visualizations_generated = Counter(
    'queryhub_visualizations_generated_total',
    'Total visualizations generated',
    ['intent', 'viz_type']
)

visualization_intent = Counter(
    'queryhub_visualization_intent_total',
    'Visualization intent detection',
    ['intent']
)

charts_per_query = Histogram(
    'queryhub_charts_per_query',
    'Number of charts generated per query',
    buckets=(0, 1, 2, 3, 5, 10, 15, 20, float('inf'))
)

gcs_upload_status = Counter(
    'queryhub_gcs_upload_status_total',
    'GCS upload success/failure',
    ['status']
)

# ============================================================================
# SYSTEM HEALTH METRICS
# ============================================================================

active_sessions = Gauge(
    'queryhub_active_sessions',
    'Number of active sessions'
)

agent_initialization_status = Gauge(
    'queryhub_agent_initialization_status',
    'Agent initialization status (1=ready, 0=not ready)'
)

system_uptime_seconds = Counter(
    'queryhub_system_uptime_seconds_total',
    'System uptime in seconds'
)

query_results_rows = Histogram(
    'queryhub_query_results_rows',
    'Number of rows returned by queries',
    buckets=(0, 10, 50, 100, 500, 1000, 5000, 10000, 50000, float('inf'))
)

# ============================================================================
# SYSTEM RESOURCE UPDATE FUNCTION
# ============================================================================

def update_system_metrics():
    """Update system resource metrics (CPU, Memory, Disk)"""
    try:
        system_cpu_usage.set(psutil.cpu_percent(interval=0.1))
        
        memory = psutil.virtual_memory()
        system_memory_usage.set(memory.percent)
        system_memory_available.set(memory.available)
        
        disk = psutil.disk_usage('/')
        system_disk_usage.set(disk.percent)
        
        process = psutil.Process(os.getpid())
        process_cpu_usage.set(process.cpu_percent(interval=0.1))
        process_memory_usage.set(process.memory_info().rss)
        
    except Exception as e:
        print(f"Error updating system metrics: {e}")


# ============================================================================
# TRACKING FUNCTIONS
# ============================================================================

def track_query_request(user_id: str, success: bool):
    """Track query request with success/failure"""
    status = 'success' if success else 'failure'
    query_requests_total.labels(user_id=user_id, status=status).inc()


def track_retry_count(retry_count: int):
    """Track number of retries for a query"""
    retry_attempts.observe(retry_count)


def track_database_selection(db_name: str, user_id: str, similarity: float):
    """Track database selection"""
    database_queries.labels(db_name=db_name, user_id=user_id).inc()
    database_selection_similarity.observe(similarity)


def track_visualization_intent(intent: str):
    """Track visualization intent (bi/eda)"""
    visualization_intent.labels(intent=intent).inc()


def track_charts_generated(count: int):
    """Track number of charts generated"""
    charts_per_query.observe(count)


def track_query_result_size(row_count: int):
    """Track size of query results"""
    query_results_rows.observe(row_count)


def track_workflow_error(error_stage: str, error_type: str):
    """Track errors at different workflow stages"""
    workflow_errors.labels(error_stage=error_stage, error_type=error_type).inc()


def track_sql_error(db_name: str, db_type: str, error_message: str):
    """Track SQL execution errors"""
    error_type = 'syntax_error' if 'syntax' in error_message.lower() else 'execution_error'
    sql_execution_errors.labels(
        db_name=db_name,
        db_type=db_type,
        error_type=error_type
    ).inc()


def track_validation_failure(failure_type: str):
    """Track SQL validation failures"""
    sql_validation_failures.labels(failure_type=failure_type).inc()


# ============================================================================
# SQL COMPLEXITY TRACKING FUNCTIONS (NEW)
# ============================================================================

def track_sql_complexity(complexity_analysis: dict, db_type: str = "unknown"):
    """
    Track SQL complexity metrics.
    
    Args:
        complexity_analysis: Dict from SQLComplexityAnalyzer.analyze()
        db_type: Database type (postgres, mysql, etc.)
    """
    primary_complexity = complexity_analysis.get('primary_complexity', 'unknown')
    all_complexities = complexity_analysis.get('all_complexities', [])
    details = complexity_analysis.get('details', {})
    complexity_score = complexity_analysis.get('complexity_score', 0)
    
    # Track primary complexity distribution
    sql_complexity_distribution.labels(
        complexity_type=primary_complexity,
        db_type=db_type
    ).inc()
    
    # Track complexity score
    sql_complexity_score.labels(db_type=db_type).observe(complexity_score)
    
    # Track all detected features
    for complexity in all_complexities:
        sql_features_detected.labels(
            feature_type=complexity,
            db_type=db_type
        ).inc()
    
    # Track specific metrics from details
    if 'multiple_joins' in details:
        join_count = details['multiple_joins'].get('join_count', 0)
        sql_join_count.labels(db_type=db_type).observe(join_count)
    elif 'single_join' in details:
        sql_join_count.labels(db_type=db_type).observe(1)
    
    if 'subqueries' in details:
        nesting_level = details['subqueries'].get('nesting_level', 0)
        sql_subquery_nesting_level.labels(db_type=db_type).observe(nesting_level)
    
    sql_average_complexity_score.labels(db_type=db_type).set(complexity_score)


def get_complexity_summary() -> dict:
    """Get a summary of SQL complexity metrics"""
    return {
        "message": "Use Prometheus queries to view complexity metrics",
        "metrics": [
            "queryhub_sql_complexity_distribution_total",
            "queryhub_sql_complexity_score",
            "queryhub_sql_features_detected_total",
            "queryhub_sql_average_complexity_score",
            "queryhub_sql_join_count",
            "queryhub_sql_subquery_nesting_level"
        ]
    }


# ============================================================================
# LLM TOKEN TRACKING FUNCTIONS
# ============================================================================

def track_llm_generation(
    operation: str,
    model: str,
    time_to_first_token: float,
    total_time: float,
    total_tokens: int
):
    """Track LLM generation metrics"""
    llm_time_to_first_token.labels(
        operation=operation,
        model=model
    ).observe(time_to_first_token)
    
    llm_total_generation_time.labels(
        operation=operation,
        model=model
    ).observe(total_time)
    
    llm_tokens_generated.labels(
        operation=operation,
        model=model
    ).inc(total_tokens)
    
    if total_time > 0:
        tokens_per_sec = total_tokens / total_time
        llm_tokens_per_second.labels(
            operation=operation,
            model=model
        ).set(tokens_per_sec)
        
        avg_time_per_token = total_time / total_tokens if total_tokens > 0 else 0
        llm_average_time_per_token.labels(
            operation=operation,
            model=model
        ).set(avg_time_per_token)


# ============================================================================
# CONTEXT MANAGERS FOR EASY TIMING
# ============================================================================

@contextmanager
def time_block(metric: Histogram, **label_kwargs):
    """Context manager to time a code block"""
    start = time.time()
    try:
        yield
    finally:
        duration = time.time() - start
        if label_kwargs:
            metric.labels(**label_kwargs).observe(duration)
        else:
            metric.observe(duration)


@contextmanager
def track_llm_timing(operation: str, model: str):
    """Context manager to track LLM generation timing"""
    class LLMTracker:
        def __init__(self):
            self.start_time = time.time()
            self.first_token_time = None
            self.total_tokens = 0
            
        def mark_first_token(self):
            if self.first_token_time is None:
                self.first_token_time = time.time()
                
        def set_total_tokens(self, count: int):
            self.total_tokens = count
    
    tracker = LLMTracker()
    try:
        yield tracker
    finally:
        total_time = time.time() - tracker.start_time
        ttft = (tracker.first_token_time - tracker.start_time) if tracker.first_token_time else 0
        
        if tracker.total_tokens > 0:
            track_llm_generation(
                operation=operation,
                model=model,
                time_to_first_token=ttft,
                total_time=total_time,
                total_tokens=tracker.total_tokens
            )


# ============================================================================
# REQUESTS PER SECOND CALCULATOR
# ============================================================================

class RequestRateTracker:
    """Tracks request rate over time windows"""
    def __init__(self, window_seconds: int = 60):
        self.window_seconds = window_seconds
        self.request_times = []
    
    def record_request(self):
        current_time = time.time()
        self.request_times.append(current_time)
        
        cutoff_time = current_time - self.window_seconds
        self.request_times = [t for t in self.request_times if t > cutoff_time]
        
        rps = len(self.request_times) / self.window_seconds
        requests_per_second.set(rps)
        
        return rps


_rps_tracker = RequestRateTracker(window_seconds=60)


def record_request():
    """Record a request and update RPS metric"""
    return _rps_tracker.record_request()